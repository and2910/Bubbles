{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "300c34ab",
   "metadata": {},
   "source": [
    "## Negative Selection data preparation and file creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77d00d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59d4f006",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_files = pd.read_csv(r'C:\\Users\\B420615\\OneDrive - Standard Bank\\Py\\SNS_Control.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "362a73c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_files = ns_files['Files'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa9d3381",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = glob.glob(r'C:\\Users\\B420615.STANLIB\\Neg_Sel\\*.csv')\n",
    "\n",
    "#create two lists of desired column names - one for all columns and one for data columns\n",
    "adjcols = ['Date','Ticker','Name','BM','AdjfcfY','CECP','TR_1M','Price','FCFY','MCap','TR_12-1','best_eps_chg','rec_chg12M','tp_chg','fcf_me','fcf_at','seas_1_1an','rec_chg']\n",
    "data_cols = ['BM','AdjfcfY','CECP','TR_1M','Price','FCFY','MCap','TR_12-1','best_eps_chg','rec_chg12M','tp_chg','fcf_me','fcf_at','seas_1_1an','rec_chg']\n",
    "cols_with_commas = ['Price','MCap']\n",
    "cols_to_avg = ['BM','AdjfcfY','TR_1M','FCFY','TR_12-1','best_eps_chg','rec_chg12M','tp_chg','fcf_me','fcf_at','seas_1_1an']\n",
    "cols_to_zero = ['CECP']\n",
    "excl_cols = ['rec_chg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e76460b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in ns_files[-1:]:\n",
    "    try:\n",
    "        neg_sel_df = pd.read_csv(rf'C:\\Users\\B420615\\OneDrive - Standard Bank\\Neg_Sel\\{file}.csv', thousands=',')\n",
    "        #neg_sel_df['Date'] = pd.to_datetime(neg_sel_df['Date'], format='%Y%m%d')\n",
    "\n",
    "\n",
    "        # clean data so that all values, apart from naming values, and including NaNs, are reflected as float values. Delete unneeded column\n",
    "        neg_sel_df = neg_sel_df[neg_sel_df['Ticker'].notna()] \n",
    "        neg_sel_df.drop(['EPS_ESTIMATE_CHG'], axis=1,inplace=True)\n",
    "        \n",
    "        column_mapping = {\n",
    "            'Date': 'Date',\n",
    "            'Ticker': 'Ticker',\n",
    "            'Short Name': 'Name',\n",
    "            'BENEISH-M': 'BM',\n",
    "            'AdjFCFYield': 'AdjfcfY',\n",
    "            'ChgEstimateVSChgPrice': 'CECP',\n",
    "            'Total Return:M-1': 'TR_1M',\n",
    "            'FCF Yld:Y': 'FCFY',\n",
    "            'TR_Momentum': 'TR_12-1',\n",
    "            'best_eps_chg': 'best_eps_chg',\n",
    "            'rec_chg_12M': 'rec_chg12M',\n",
    "            'tp_change': 'tp_chg',\n",
    "            'fcf_me': 'fcf_me',\n",
    "            'fcf_at': 'fcf_at',\n",
    "            'seas_1_1an': 'seas_1_1an',\n",
    "            'rec_chg': 'rec_chg',\n",
    "            'Market Cap': 'MCap',\n",
    "            'Last Px': 'Price'\n",
    "        }\n",
    "        \n",
    "        # Rename columns\n",
    "        neg_sel_df = neg_sel_df.rename(columns=column_mapping)\n",
    "        #replace NA's with NaN       \n",
    "        neg_sel_df.replace('N.A.', np.nan, inplace=True)\n",
    "        \n",
    "        def convert_to_float(value):\n",
    "            if isinstance(value, str):  # Check if the value is a string\n",
    "                value = value.replace(',', '')  # Remove commas\n",
    "                try:\n",
    "                    return float(value)  # Convert to float\n",
    "                except ValueError:\n",
    "                    return None  # Return None if conversion fails\n",
    "            return value  # Return the value unchanged if not a string\n",
    "        \n",
    "        neg_sel_df[data_cols] = neg_sel_df[data_cols].map(convert_to_float)\n",
    "       \n",
    "        #   replace values with mean value where required \n",
    "        for col in cols_to_avg:\n",
    "            if col in neg_sel_df.columns:\n",
    "                mean_value = neg_sel_df[col].astype(float).mean()\n",
    "                neg_sel_df[col] = neg_sel_df[col].fillna(mean_value)\n",
    "\n",
    "        #   replace values with zero where required\n",
    "        for col in cols_to_zero:\n",
    "            if col in neg_sel_df.columns:\n",
    "                neg_sel_df[col] = neg_sel_df[col].fillna(0.0)\n",
    "\n",
    "        # calculate z-score for all cols where  mean values are imputed and append to existing data frame\n",
    "        z_scores = neg_sel_df[cols_to_avg].apply(zscore)\n",
    "        z_scores.columns = [f'z_{col}' for col in cols_to_avg]\n",
    "        neg_sel_df = pd.concat([neg_sel_df, z_scores], axis=1)\n",
    "\n",
    "        # calculate z-score for all cols where  Nan replaced with zero\n",
    "        z_scores = neg_sel_df[cols_to_zero].apply(zscore)\n",
    "        z_scores.columns = [f'z_{col}' for col in cols_to_zero]\n",
    "        neg_sel_df = pd.concat([neg_sel_df, z_scores], axis=1)\n",
    "\n",
    "        # create a list of excluded stocks\n",
    "        excl_stocks = []\n",
    "        for index,row in neg_sel_df.iterrows():\n",
    "            if pd.isna(row['rec_chg']):\n",
    "                excl_stocks.append(row['Ticker'])\n",
    "\n",
    "        # drop na rows where NaN values are in excl_cols\n",
    "        neg_sel_df = neg_sel_df.dropna(subset = ['rec_chg'])\n",
    "\n",
    "        #calculate z scores for excl_cols\n",
    "        z_scores = neg_sel_df[excl_cols].apply(zscore)\n",
    "        z_scores.columns = [f'z_{col}' for col in excl_cols]\n",
    "\n",
    "        # add z-score columns to the original DataFrame\n",
    "        neg_sel_df = pd.concat([neg_sel_df, z_scores], axis=1)\n",
    "\n",
    "        #calculate z-scores for NS using specified weights\n",
    "        # Calculate Neg_Sel z-scores using specified weights\n",
    "        columns = ['z_TR_12-1','z_CECP', 'z_best_eps_chg', 'z_tp_chg', 'z_rec_chg', 'z_fcf_me','z_fcf_at','z_BM']\n",
    "        neg_sel_df['Neg_Sel'] = neg_sel_df[columns].mean(axis=1)\n",
    "        \n",
    "        \n",
    "        # Divide universe into quintiles\n",
    "        neg_sel_df['NS_Quintile'] = pd.qcut(neg_sel_df['Neg_Sel'], q=5, labels=False)+1       \n",
    "\n",
    "        # Post revised and processed stock ranking file\n",
    "        output_file_path = rf'C:\\Users\\B420615\\OneDrive - Standard Bank\\Neg_Sel\\Neg_Sel_S{file}.csv'\n",
    "        neg_sel_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file}: {e}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9017b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
